{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# profiling.ipynb\n",
    "\n",
    "Code for profiling pytorch dataloaders\n",
    "\n",
    "* Created on Thursday May 15th, 2025\n",
    "* Created by Jacob A Rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.data = torch.randn(10, 3, 224, 224)\n",
    "#         self.target = torch.randint(0, 10, (10,))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         x = self.data[index]\n",
    "#         y = self.target[index]\n",
    "\n",
    "#         with record_function(\"transform1\"):\n",
    "#             x = x * 2\n",
    "\n",
    "#         with record_function(\"transform2\"):\n",
    "#             y = y + 1\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "\n",
    "# dataset = MyDataset()\n",
    "# loader = DataLoader(dataset, batch_size=5, num_workers=0)\n",
    "# with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "#     with record_function(\"loader\"):\n",
    "#         for batch in loader:\n",
    "#             pass\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "cpu_count = 0\n",
    "\n",
    "warmup_iterations = 2  # 20\n",
    "num_iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 12800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.autograd.profiler as profiler\n",
    "from tqdm import tqdm, trange\n",
    "from plantclef.pytorch.data_catalog import make_dataset\n",
    "\n",
    "\n",
    "ds = make_dataset(name=\"plantclef2024\", load_all_subsets=False, subset=\"val\")\n",
    "\n",
    "tx = ds.get_transforms(is_training=True, crop_size=518)\n",
    "ds.set_transform(tx)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count,\n",
    "    pin_memory=True,\n",
    ")\n",
    "total_samples = batch_size * num_iterations\n",
    "print(f\"Total samples: {total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.50s/it]\n",
      "100%|██████████| 50/50 [02:07<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([256, 3, 518, 518])\n",
      "labels.shape: torch.Size([256])\n",
      "Processed 49 batches\n",
      "Finished\n",
      "---------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                         loader         0.06%      78.403ms        99.95%      127.727s      127.727s       6.987ms         0.01%      127.786s      127.786s           0 b           0 b     786.11 Mb     -37.62 Gb             1  \n",
      "    enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__         4.31%        5.501s        99.89%      127.640s        2.553s        5.329s         4.17%      124.714s        2.494s           0 b     -76.77 Gb           0 b           0 b            50  \n",
      "                                              self.dataset[idx]        49.60%       63.388s        49.60%       63.388s       4.952ms       61.671s        48.26%       61.671s       4.818ms           0 b           0 b           0 b           0 b         12800  \n",
      "                                                      transform        17.82%       22.771s        23.45%       29.971s       2.341ms       22.210s        17.38%       29.199s       2.281ms      38.38 Gb           0 b           0 b           0 b         12800  \n",
      "                                                    aten::stack         0.00%       5.701ms        17.06%       21.804s     436.082ms       4.356ms         0.00%       21.804s     436.085ms      38.38 Gb           0 b           0 b           0 b            50  \n",
      "                                                      aten::cat        17.06%       21.797s        17.06%       21.797s     435.938ms       21.799s        17.06%       21.799s     435.987ms      38.38 Gb      38.38 Gb           0 b           0 b            50  \n",
      "                                                    aten::copy_         7.96%       10.171s         7.96%       10.172s     782.456us       13.160s        10.30%       13.160s       1.012ms           0 b           0 b           0 b           0 b         13000  \n",
      "                                               aten::contiguous         0.07%      83.385ms         5.50%        7.028s     549.092us     127.382ms         0.10%        6.898s     538.900us      38.38 Gb           0 b           0 b           0 b         12800  \n",
      "                                                    aten::clone         0.17%     213.441ms         5.40%        6.900s     539.061us     226.569ms         0.18%        6.771s     528.949us      38.38 Gb           0 b           0 b           0 b         12800  \n",
      "                                               aten::pin_memory         0.00%       2.181ms         3.03%        3.870s      38.696ms       1.826ms         0.00%        3.870s      38.699ms           0 b           0 b           0 b           0 b           100  \n",
      "                                              aten::_pin_memory         0.00%       4.898ms         3.02%        3.864s      38.644ms       5.020ms         0.00%        3.866s      38.656ms           0 b           0 b           0 b           0 b           100  \n",
      "                                                       aten::to         0.00%     923.800us         0.01%       7.921ms      52.807us     999.000us         0.00%        3.065s      20.435ms           0 b           0 b      38.38 Gb           0 b           150  \n",
      "                                                 aten::_to_copy         0.00%       1.876ms         0.01%       6.610ms      66.100us       1.709ms         0.00%        3.064s      30.643ms           0 b           0 b      38.38 Gb           0 b           100  \n",
      "                                    _get_label_tensor(idx, row)         0.51%     650.194ms         0.86%        1.093s      85.368us     677.395ms         0.53%        1.112s      86.838us           0 b           0 b           0 b           0 b         12800  \n",
      "                                       _get_sample_id(idx, row)         0.39%     496.623ms         0.67%     862.546ms      67.386us     523.387ms         0.41%     885.489ms      69.179us           0 b           0 b           0 b           0 b         12800  \n",
      "---------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 127.786s\n",
      "Self CUDA time total: 127.786s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in tqdm(loader, total=warmup_iterations):\n",
    "    images, labels = batch[\"image\"], batch[\"label_idx\"]\n",
    "    i += 1\n",
    "    if i > warmup_iterations:\n",
    "        break\n",
    "\n",
    "profile_device = device.type  # \"cpu\" #\n",
    "\n",
    "with profiler.profile(\n",
    "    use_device=profile_device, profile_memory=True, with_stack=True, with_modules=True\n",
    ") as prof:\n",
    "    # Run your training loop for several iterations\n",
    "    i = 0\n",
    "    data_iter = iter(loader)\n",
    "    with profiler.record_function(\"loader\"):\n",
    "        for i in trange(num_iterations):\n",
    "            batch = next(data_iter)\n",
    "            images, labels = batch[\"image\"], batch[\"label_idx\"]\n",
    "            images, labels = (\n",
    "                images.to(device, non_blocking=True),\n",
    "                labels.to(device, non_blocking=True),\n",
    "            )\n",
    "    assert images.device.type == device.type\n",
    "    assert labels.device.type == device.type\n",
    "    print(f\"images.shape: {images.shape}\")\n",
    "    print(f\"labels.shape: {labels.shape}\")\n",
    "    print(f\"Processed {i} batches\")\n",
    "\n",
    "print(\"Finished\")\n",
    "\n",
    "print(\n",
    "    prof.key_averages().table(\n",
    "        sort_by=\"cuda_time_total\", row_limit=15, max_name_column_width=90\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.16746748470098"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12800 / 127.786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([128, 3, 518, 518])\n",
      "labels.shape: torch.Size([128])\n",
      "Processed 4 batches\n"
     ]
    }
   ],
   "source": [
    "assert images.device.type == device.type\n",
    "assert labels.device.type == device.type\n",
    "\n",
    "print(f\"images.shape: {images.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")\n",
    "print(f\"Processed {i} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                           loader         0.04%      19.918ms       100.00%       55.146s       55.146s           0 b           0 b             1  \n",
      "    enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__        99.96%       55.124s        99.96%       55.124s        5.512s           0 b           0 b            10  \n",
      "                                                         aten::to         0.00%     124.861us         0.00%       1.711ms      85.540us           0 b           0 b            20  \n",
      "                                                   aten::_to_copy         0.00%     209.192us         0.00%       1.586ms      79.297us           0 b           0 b            20  \n",
      "                                              aten::empty_strided         0.00%     295.121us         0.00%     819.880us      40.994us           0 b           0 b            20  \n",
      "                                                      aten::copy_         0.00%     216.819us         0.00%     556.873us      27.844us           0 b           0 b            20  \n",
      "                                                       cudaMalloc         0.00%     514.778us         0.00%     514.778us     514.778us           0 b           0 b             1  \n",
      "                                                  cudaMemcpyAsync         0.00%     340.054us         0.00%     340.054us      17.003us           0 b           0 b            20  \n",
      "                                                  cudaEventRecord         0.00%     126.958us         0.00%     126.958us       7.053us           0 b           0 b            18  \n",
      "                                                   cudaEventQuery         0.00%     114.910us         0.00%     114.910us       7.182us           0 b           0 b            16  \n",
      "-----------------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 55.146s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    prof.key_averages().table(\n",
    "        sort_by=\"cpu_time_total\", row_limit=10, max_name_column_width=90\n",
    "    )\n",
    ")\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         216 function calls (209 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:359(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:678(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:986(__and__)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:249(compile)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:288(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:516(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:622(_code)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:783(compile)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_compile.py:87(_compile)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:161(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 sre_parse.py:165(__getitem__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:173(append)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_parse.py:175(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:234(__next)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:250(match)\n",
      "        6    0.000    0.000    0.000    0.000 sre_parse.py:255(get)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(tell)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:436(_parse_sub)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:494(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:944(parse)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method builtins.exec}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "    29/26    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import cProfile\n",
    "\n",
    "# cProfile.run('re.compile(\"foo|bar\")')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
