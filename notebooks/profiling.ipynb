{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# profiling.ipynb\n",
    "\n",
    "Code for profiling pytorch dataloaders\n",
    "\n",
    "* Created on Thursday May 15th, 2025\n",
    "* Created by Jacob A Rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 loader        10.56%      11.637ms       100.00%     110.171ms     110.171ms             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.05%      15.478ms        77.07%      84.905ms      28.302ms             3  \n",
      "                                             transform1        11.56%      12.737ms        28.93%      31.876ms       3.188ms            10  \n",
      "                                              aten::mul        12.55%      13.831ms        17.37%      19.139ms       1.914ms            10  \n",
      "                                           aten::select        12.85%      14.155ms        16.49%      18.172ms     908.578us            20  \n",
      "                                            aten::stack         3.47%       3.823ms        12.90%      14.212ms       3.553ms             4  \n",
      "                                             aten::item         0.54%     591.871us        10.27%      11.316ms      11.316ms             1  \n",
      "                              aten::_local_scalar_dense         9.73%      10.724ms         9.73%      10.724ms      10.724ms             1  \n",
      "                                              aten::cat         4.87%       5.369ms         9.22%      10.160ms       2.540ms             4  \n",
      "                                               aten::to         1.47%       1.615ms         4.82%       5.308ms     530.795us            10  \n",
      "                                             transform2         3.05%       3.364ms         4.69%       5.167ms     516.700us            10  \n",
      "                                           aten::narrow         3.34%       3.677ms         4.35%       4.792ms       2.396ms             2  \n",
      "                                       aten::as_strided         3.66%       4.035ms         3.66%       4.035ms     126.097us            32  \n",
      "                                         aten::_to_copy         1.34%       1.479ms         3.35%       3.693ms     369.329us            10  \n",
      "                                          aten::random_         2.09%       2.300ms         2.09%       2.300ms       2.300ms             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 110.171ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:2025-05-16 01:46:28 53381:53381 DeviceProperties.cpp:47] gpuGetDeviceCount failed with code 35\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(10, 3, 224, 224)\n",
    "        self.target = torch.randint(0, 10, (10,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "\n",
    "        with record_function(\"transform1\"):\n",
    "            x = x * 2\n",
    "\n",
    "        with record_function(\"transform2\"):\n",
    "            y = y + 1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "dataset = MyDataset()\n",
    "loader = DataLoader(dataset, batch_size=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"loader\"):\n",
    "        for batch in loader:\n",
    "            pass\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from plantclef.pytorch.data_catalog import make_dataset\n",
    "\n",
    "\n",
    "ds = make_dataset(name=\"plantclef2024\", load_all_subsets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "cpu_count = 0\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with profiler.profile(use_cuda=(\"cuda\" in device.type)) as prof:\n",
    "    # Run your training loop for several iterations\n",
    "    i = 0\n",
    "    for batch in loader:\n",
    "        images, labels = batch[\"image\"], batch[\"label_idx\"]\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         0.04%       2.421ms         0.04%       2.421ms      12.880us           188  \n",
      "                                          aten::random_         0.00%      23.131us         0.00%      23.131us      23.131us             1  \n",
      "                                             aten::item         0.00%       4.147us         0.00%       6.627us       6.627us             1  \n",
      "                              aten::_local_scalar_dense         0.00%       2.480us         0.00%       2.480us       2.480us             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        89.46%        4.928s       100.00%        5.509s     500.787ms            11  \n",
      "                                       aten::lift_fresh         0.02%     852.829us         0.02%     852.829us       4.561us           187  \n",
      "                                       aten::contiguous         0.02%     919.140us         5.83%     320.898ms       1.823ms           176  \n",
      "                                            aten::clone         0.04%       2.131ms         5.81%     319.979ms       1.818ms           176  \n",
      "                                       aten::empty_like         0.04%       1.969ms         0.08%       4.253ms      24.168us           176  \n",
      "                                            aten::copy_         5.69%     313.594ms         5.69%     313.594ms       1.782ms           176  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.509s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         216 function calls (209 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:359(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:678(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:986(__and__)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:249(compile)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:288(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:516(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:622(_code)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:783(compile)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_compile.py:87(_compile)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:161(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 sre_parse.py:165(__getitem__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:173(append)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_parse.py:175(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:234(__next)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:250(match)\n",
      "        6    0.000    0.000    0.000    0.000 sre_parse.py:255(get)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(tell)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:436(_parse_sub)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:494(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:944(parse)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method builtins.exec}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "    29/26    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run('re.compile(\"foo|bar\")')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
