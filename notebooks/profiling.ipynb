{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# profiling.ipynb\n",
    "\n",
    "Code for profiling pytorch dataloaders\n",
    "\n",
    "* Created on Thursday May 15th, 2025\n",
    "* Created by Jacob A Rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.data = torch.randn(10, 3, 224, 224)\n",
    "#         self.target = torch.randint(0, 10, (10,))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         x = self.data[index]\n",
    "#         y = self.target[index]\n",
    "\n",
    "#         with record_function(\"transform1\"):\n",
    "#             x = x * 2\n",
    "\n",
    "#         with record_function(\"transform2\"):\n",
    "#             y = y + 1\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "\n",
    "# dataset = MyDataset()\n",
    "# loader = DataLoader(dataset, batch_size=5, num_workers=0)\n",
    "# with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "#     with record_function(\"loader\"):\n",
    "#         for batch in loader:\n",
    "#             pass\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "dill.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BatchSampler',\n",
       " 'ChainDataset',\n",
       " 'ConcatDataset',\n",
       " 'DFIterDataPipe',\n",
       " 'DataChunk',\n",
       " 'DataLoader',\n",
       " 'Dataset',\n",
       " 'DistributedSampler',\n",
       " 'IterDataPipe',\n",
       " 'IterableDataset',\n",
       " 'MapDataPipe',\n",
       " 'RandomSampler',\n",
       " 'Sampler',\n",
       " 'SequentialSampler',\n",
       " 'StackDataset',\n",
       " 'Subset',\n",
       " 'SubsetRandomSampler',\n",
       " 'TensorDataset',\n",
       " 'WeightedRandomSampler',\n",
       " '_DatasetKind',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'argument_validation',\n",
       " 'dataloader',\n",
       " 'datapipes',\n",
       " 'dataset',\n",
       " 'default_collate',\n",
       " 'default_convert',\n",
       " 'distributed',\n",
       " 'functional_datapipe',\n",
       " 'get_worker_info',\n",
       " 'graph',\n",
       " 'graph_settings',\n",
       " 'guaranteed_datapipes_determinism',\n",
       " 'non_deterministic',\n",
       " 'random_split',\n",
       " 'runtime_validation',\n",
       " 'runtime_validation_disabled',\n",
       " 'sampler']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dir(torch.utils.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 29.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from plantclef.pytorch.data_catalog import make_dataset\n",
    "\n",
    "\n",
    "ds = make_dataset(name=\"plantclef2024\", load_all_subsets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "cpu_count = 0\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# batch = next(iter(loader))\n",
    "# type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67565/229195459.py:6: FutureWarning: The attribute `use_cuda` will be deprecated soon, please use ``use_device = 'cuda'`` instead.\n",
      "  with profiler.profile(use_cuda=(\"cuda\" in device.type)) as prof:\n",
      " 25%|██▌       | 100/400 [03:42<11:08,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        93.12%      207.415s        98.60%      219.625s        2.175s      207.490s        93.15%      219.632s        2.175s           101  \n",
      "                                            aten::copy_         2.95%        6.580s         4.34%        9.673s     725.573us        9.759s         4.38%        9.759s     731.962us         13332  \n",
      "                                       aten::contiguous         0.04%      83.118ms         2.06%        4.588s     354.916us     137.034ms         0.06%        4.634s     358.417us         12928  \n",
      "                                            aten::clone         0.09%     196.654ms         2.00%        4.459s     344.888us     209.381ms         0.09%        4.497s     347.817us         12928  \n",
      "                                            aten::stack         0.00%       8.900ms         1.78%        3.960s      39.205ms       6.208ms         0.00%        3.960s      39.209ms           101  \n",
      "                                              aten::cat         1.77%        3.944s         1.77%        3.948s      39.090ms        3.949s         1.77%        3.953s      39.138ms           101  \n",
      "                                       aten::pin_memory         0.00%       2.758ms         1.55%        3.456s      17.107ms       3.499ms         0.00%        3.456s      17.111ms           202  \n",
      "                                      aten::_pin_memory         0.00%       9.413ms         1.55%        3.447s      17.065ms     809.716ms         0.36%        3.448s      17.069ms           202  \n",
      "                                               aten::to         0.00%       1.773ms         1.40%        3.110s      10.265ms       3.483ms         0.00%        3.112s      10.270ms           303  \n",
      "                                         aten::_to_copy         0.00%       4.538ms         1.40%        3.108s      15.385ms       4.867ms         0.00%        3.108s      15.388ms           202  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 222.738s\n",
      "Self CUDA time total: 222.743s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warmup_iterations = 5\n",
    "num_iterations = 100\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "i = 0\n",
    "for batch in tqdm(loader, total=warmup_iterations):\n",
    "    images, labels = batch[\"image\"], batch[\"label_idx\"]\n",
    "    i += 1\n",
    "    if i > warmup_iterations:\n",
    "        break\n",
    "\n",
    "with profiler.profile(use_device=device.type) as prof:\n",
    "    # Run your training loop for several iterations\n",
    "    i = 0\n",
    "    for batch in tqdm(loader, total=num_iterations):\n",
    "        images, labels = batch[\"image\"], batch[\"label_idx\"]\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        i += 1\n",
    "        if i > num_iterations:\n",
    "            break\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ensure_function_events',\n",
       " '_function_events',\n",
       " '_needs_processing',\n",
       " '_old_function_events',\n",
       " '_parse_kineto_results',\n",
       " '_prepare_trace',\n",
       " '_start_trace',\n",
       " '_stats',\n",
       " 'acc_events',\n",
       " 'config',\n",
       " 'create_trace_id',\n",
       " 'custom_trace_id_callback',\n",
       " 'default_trace_id',\n",
       " 'enabled',\n",
       " 'entered',\n",
       " 'experimental_config',\n",
       " 'export_chrome_trace',\n",
       " 'export_stacks',\n",
       " 'function_events',\n",
       " 'key_averages',\n",
       " 'kineto_activities',\n",
       " 'kineto_results',\n",
       " 'profile_memory',\n",
       " 'profiler_kind',\n",
       " 'profiling_end_time_ns',\n",
       " 'profiling_start_time_ns',\n",
       " 'record_shapes',\n",
       " 'self_cpu_time_total',\n",
       " 'table',\n",
       " 'toggle_collection_dynamic',\n",
       " 'total_average',\n",
       " 'trace_id',\n",
       " 'use_cpu',\n",
       " 'use_cuda',\n",
       " 'use_device',\n",
       " 'with_flops',\n",
       " 'with_modules',\n",
       " 'with_stack']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprof\u001b[49m\u001b[38;5;241m.\u001b[39mkey_averages()\u001b[38;5;241m.\u001b[39mtable(sort_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda_time_total\u001b[39m\u001b[38;5;124m\"\u001b[39m, row_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_name_column_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prof' is not defined"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    prof.key_averages().table(\n",
    "        sort_by=\"cuda_time_total\", row_limit=10, max_name_column_width=90\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        90.02%        2.589s        98.34%        2.828s     257.114ms        2.590s        90.12%        2.828s     257.131ms            11  \n",
      "                                            aten::copy_         3.22%      92.693ms         4.70%     135.118ms     614.174us     136.342ms         4.74%     136.342ms     619.736us           220  \n",
      "                                       aten::pin_memory         0.01%     356.737us         4.08%     117.374ms       5.335ms     427.000us         0.01%     117.432ms       5.338ms            22  \n",
      "                                      aten::_pin_memory         0.07%       2.016ms         4.05%     116.330ms       5.288ms      81.109ms         2.82%     116.392ms       5.291ms            22  \n",
      "                                       aten::contiguous         0.06%       1.823ms         2.31%      66.398ms     377.263us       2.310ms         0.08%      66.781ms     379.438us           176  \n",
      "                                            aten::clone         0.09%       2.480ms         2.22%      63.973ms     363.485us       2.855ms         0.10%      64.471ms     366.312us           176  \n",
      "                                            aten::stack         0.05%       1.384ms         1.83%      52.748ms       4.795ms       1.244ms         0.04%      52.783ms       4.798ms            11  \n",
      "                                              aten::cat         1.73%      49.875ms         1.77%      50.949ms       4.632ms      50.188ms         1.75%      51.252ms       4.659ms            11  \n",
      "                                               aten::to         0.01%     246.273us         1.55%      44.703ms       1.355ms     327.000us         0.01%      44.768ms       1.357ms            33  \n",
      "                                         aten::_to_copy         0.02%     497.712us         1.54%      44.391ms       2.018ms     550.000us         0.02%      44.441ms       2.020ms            22  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.876s\n",
      "Self CUDA time total: 2.874s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         216 function calls (209 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:359(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:678(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:986(__and__)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:249(compile)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:288(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:265(_compile_charset)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:292(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:477(_get_iscased)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:485(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:516(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:560(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:619(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:622(_code)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:783(compile)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_compile.py:87(_compile)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:112(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:161(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 sre_parse.py:165(__getitem__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:173(append)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_parse.py:175(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:225(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:234(__next)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:250(match)\n",
      "        6    0.000    0.000    0.000    0.000 sre_parse.py:255(get)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(tell)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:436(_parse_sub)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:494(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:82(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:928(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:944(parse)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method builtins.exec}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "    29/26    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run('re.compile(\"foo|bar\")')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
