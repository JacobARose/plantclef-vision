{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding workflow using DINOv2\n",
    "\n",
    "This notebook focuses on the **Feature Extraction** pipeline. \n",
    "\n",
    "We utilize the fine-tuned model **ViTD2PC24All** ([DINOv2](https://dinov2.metademolab.com/)) to extract high-dimensional embeddings from the single-label train images and multi-label test images.\n",
    "\n",
    "We'll **visualize**, **tile**, and **process** these embeddings to support patch-wise multi-label inference using PyTorch and Faiss.\n",
    "\n",
    "![diagram](../images/pytorch-webinar-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to load the parquet file from disk and visualize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chop_threshold',\n",
       " 'colheader_justify',\n",
       " 'date_dayfirst',\n",
       " 'date_yearfirst',\n",
       " 'encoding',\n",
       " 'expand_frame_repr',\n",
       " 'float_format',\n",
       " 'html',\n",
       " 'large_repr',\n",
       " 'max_categories',\n",
       " 'max_columns',\n",
       " 'max_colwidth',\n",
       " 'max_dir_items',\n",
       " 'max_info_columns',\n",
       " 'max_info_rows',\n",
       " 'max_rows',\n",
       " 'max_seq_items',\n",
       " 'memory_usage',\n",
       " 'min_rows',\n",
       " 'multi_sparse',\n",
       " 'notebook_repr_html',\n",
       " 'pprint_nest_depth',\n",
       " 'precision',\n",
       " 'show_dimensions',\n",
       " 'unicode',\n",
       " 'width']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rich import print as pprint\n",
    "\n",
    "pd.options.display.precision = 2\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 25\n",
    "\n",
    "# root_dir = \"/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025\"\n",
    "# dataset_dir = \"/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/competition-metadata/PlantCLEF2025_test_images/PlantCLEF2025_test_images\"\n",
    "# hf_dataset_dir = \"/teamspace/studios/this_studio/plantclef-vision/data/parquet/plantclef2025/full_test/HF_dataset\"\n",
    "dir(pd.options.display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantclef.datasets.preprocessing.hf.train_val_test_subsets_to_hf import (\n",
    "    Config,\n",
    "    preprocess_hf_dataset,\n",
    "    HFDataset,\n",
    ")\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shortest_edge': 588}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Config</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'train_val_test'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">x_col</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'image_path'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">label_col</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'species_id'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">target_col</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'label_idx'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">image_size</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'shortest_edge'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">588</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interpolation_mode</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'nearest'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">dataset_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/PlantCLEF2024singleplanttrainin</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gdata_800_max_side_size/images_max_side_800'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_cache_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/competition-metadata/Pl</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">antCLEF2024_single_plant_training_metadata.parquet'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hf_datasets_root_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/hf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hf_dataset_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/hf/plantclef2025/single_label_train_val_te</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">st'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hf_dataset_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/hf/plantclef2025/single_label_train_val_t</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">est/shortest_edge_588'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'train_val_test'\u001b[0m,\n",
       "    \u001b[33mx_col\u001b[0m=\u001b[32m'image_path'\u001b[0m,\n",
       "    \u001b[33mlabel_col\u001b[0m=\u001b[32m'species_id'\u001b[0m,\n",
       "    \u001b[33mtarget_col\u001b[0m=\u001b[32m'label_idx'\u001b[0m,\n",
       "    \u001b[33mimage_size\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'shortest_edge'\u001b[0m: \u001b[1;36m588\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33minterpolation_mode\u001b[0m=\u001b[32m'nearest'\u001b[0m,\n",
       "    \u001b[33mdataset_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/PlantCLEF2024singleplanttrainin\u001b[0m\n",
       "\u001b[32mgdata_800_max_side_size/images_max_side_800'\u001b[0m,\n",
       "    \u001b[33mmetadata_cache_path\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/competition-metadata/Pl\u001b[0m\n",
       "\u001b[32mantCLEF2024_single_plant_training_metadata.parquet'\u001b[0m,\n",
       "    \u001b[33mhf_datasets_root_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/hf'\u001b[0m,\n",
       "    \u001b[33mhf_dataset_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/hf/plantclef2025/single_label_train_val_te\u001b[0m\n",
       "\u001b[32mst'\u001b[0m,\n",
       "    \u001b[33mhf_dataset_path\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/hf/plantclef2025/single_label_train_val_t\u001b[0m\n",
       "\u001b[32mest/shortest_edge_588'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cache Found] previously preprocessed metadata cache, loading from cache file and skipping preprocessing\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.show()\n",
    "\n",
    "\n",
    "dataset_subsets = preprocess_hf_dataset(cfg)\n",
    "ds = dataset_subsets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_shards\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindices_cache_file_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return the `index`-nth shard from dataset split into `num_shards` pieces.\n",
      "\n",
      "This shards deterministically. `dataset.shard(n, i)` splits the dataset into contiguous chunks,\n",
      "so it can be easily concatenated back together after processing. If `len(dataset) % n == l`, then the\n",
      "first `l` dataset each have length `(len(dataset) // n) + 1`, and the remaining dataset have length `(len(dataset) // n)`.\n",
      "`datasets.concatenate_datasets([dset.shard(n, i) for i in range(n)])` returns a dataset with the same order as the original.\n",
      "\n",
      "Note: n should be less or equal to the number of elements in the dataset `len(dataset)`.\n",
      "\n",
      "On the other hand, `dataset.shard(n, i, contiguous=False)` contains all elements of the dataset whose index mod `n = i`.\n",
      "\n",
      "Be sure to shard before using any randomizing operator (such as `shuffle`).\n",
      "It is best if the shard operator is used early in the dataset pipeline.\n",
      "\n",
      "Args:\n",
      "    num_shards (`int`):\n",
      "        How many shards to split the dataset into.\n",
      "    index (`int`):\n",
      "        Which shard to select and return.\n",
      "    contiguous: (`bool`, defaults to `True`):\n",
      "        Whether to select contiguous blocks of indices for shards.\n",
      "    keep_in_memory (`bool`, defaults to `False`):\n",
      "        Keep the dataset in memory instead of writing it to a cache file.\n",
      "    indices_cache_file_name (`str`, *optional*):\n",
      "        Provide the name of a path for the cache file. It is used to store the\n",
      "        indices of each shard instead of the automatically generated cache file name.\n",
      "    writer_batch_size (`int`, defaults to `1000`):\n",
      "        This only concerns the indices mapping.\n",
      "        Number of indices per write operation for the cache file writer.\n",
      "        This value is a good trade-off between memory usage during the processing, and processing speed.\n",
      "        Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `map`.\n",
      "\n",
      "Example:\n",
      "\n",
      "```py\n",
      ">>> from datasets import load_dataset\n",
      ">>> ds = load_dataset(\"cornell-movie-review-data/rotten_tomatoes\", split=\"validation\")\n",
      ">>> ds\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1066\n",
      "})\n",
      ">>> ds.shard(num_shards=2, index=0)\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 533\n",
      "})\n",
      "```\n",
      "\u001b[0;31mFile:\u001b[0m      /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/arrow_dataset.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "ds.shard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "shard_size = batch_size * 4\n",
    "resume_from_shard = 54\n",
    "total_size = len(ds)\n",
    "num_proc = os.cpu_count()\n",
    "num_shards = total_size // shard_size + 1\n",
    "shard_idx = resume_from_shard or 0\n",
    "\n",
    "\n",
    "shards = ds.batch(shard_size).skip(shard_idx)\n",
    "\n",
    "num_shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634562"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (total_size // shard_size)*num_shards\n",
    "# shard_size*num_shards - total_size\n",
    "# total_size\n",
    "# num_shards = total_size // shard_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from torchvision import transforms\n",
    "from typing import Dict, Any\n",
    "\n",
    "# tx = get_dict_transform(\n",
    "#     transform_kwargs={\"image_size\": {\"shortest_edge\": 716}}, input_columns=cfg.x_col\n",
    "# )\n",
    "\n",
    "\n",
    "# @staticmethod\n",
    "# def aspect_ratio(img: torch.Tensor):\n",
    "\n",
    "#     minside = np.min(img.shape[1:])\n",
    "#     maxside = np.max(img.shape[1:])\n",
    "\n",
    "#     aspect_ratio = maxside / minside\n",
    "#     return aspect_ratio\n",
    "\n",
    "\n",
    "class ImageProcessor:\n",
    "    interpolation_modes: Dict[str, Any] = {\n",
    "        \"BICUBIC\": transforms.InterpolationMode.BICUBIC,\n",
    "        \"BILINEAR\": transforms.InterpolationMode.BILINEAR,\n",
    "        \"BOX\": transforms.InterpolationMode.BOX,\n",
    "        \"HAMMING\": transforms.InterpolationMode.HAMMING,\n",
    "        \"LANCZOS\": transforms.InterpolationMode.LANCZOS,\n",
    "        \"NEAREST\": transforms.InterpolationMode.NEAREST,\n",
    "        \"NEAREST_EXACT\": transforms.InterpolationMode.NEAREST_EXACT,\n",
    "    }\n",
    "\n",
    "    def __init__(self, image_size: Dict[str, int], interpolation_mode: str = \"BICUBIC\"):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.interpolation_mode = self.interpolation_modes[interpolation_mode]\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        self.resize_tx = transforms.Resize(\n",
    "            size=self.image_size[\"shortest_edge\"],\n",
    "            interpolation=self.interpolation_mode,\n",
    "            max_size=None,\n",
    "            antialias=True,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def read_image(cls, path):\n",
    "        with PIL.Image.open(path) as img:\n",
    "            return img.load()\n",
    "\n",
    "    def resize_image(self, image):\n",
    "        return self.resize_tx(image)\n",
    "\n",
    "    def process_func(self, path):\n",
    "        \"\"\"\n",
    "        TBD: Write the specific functions for this wrapper\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        img = self.read_image(path)\n",
    "        return self.resize_image(img)\n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        return [self.process_func(path) for path in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 170.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_path', 'label_idx', 'image_name', 'organ', 'species_id', 'obs_id', 'author', 'altitude', 'latitude', 'longitude', 'species', 'genus', 'family', 'learn_tag', '__index_level_0__'],\n",
       "    num_rows: 256\n",
       "})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for shard in tqdm(shards):\n",
    "    shard = HFDataset.from_dict(shard)\n",
    "\n",
    "    # processed_shard = shard.map(\n",
    "    #     process_batch,\n",
    "    #     batched=True,\n",
    "    #     batch_size=batch_size,\n",
    "    #     num_proc=num_proc,\n",
    "    #     desc=f\"Processing shard {shard_idx} of {num_shards}\",\n",
    "    # )\n",
    "\n",
    "    # shard_path = cfg.get_shard_path(shard_idx, shard_size, total_size)\n",
    "\n",
    "    # processed_shard.save_to_disk(shard_path)\n",
    "\n",
    "    # shard_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def measure_image(image_path):\n",
    "    with PIL.Image.open(image_path) as img:\n",
    "        width, height = img.size\n",
    "    return {\"width\": width, \"height\": height}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examples_iterable': {'shard_idx': 0,\n",
       "  'shard_example_idx': 0,\n",
       "  'type': 'ArrowExamplesIterable'},\n",
       " 'epoch': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# batches_ds_list = [HFDataset.from_dict(b) for b in tqdm(batches.take(10))]\n",
    "# batches_ds = concatenate_datasets(batches_ds_list)\n",
    "# from datasets import Dataset as HFDataset, Image\n",
    "# import os\n",
    "\n",
    "# batch = HFDataset.from_dict(batches[0])\n",
    "# batch\n",
    "\n",
    "\n",
    "# tx = get_dict_transform(\n",
    "#     transform_kwargs={\"image_size\": {\"shortest_edge\": 716}}, input_columns=cfg.x_col\n",
    "# )\n",
    "\n",
    "# # print(f\"[INITIATING dataset.map(resize)] -- using num_proc={os.cpu_count()}\")\n",
    "# batch = batch.cast_column(cfg.x_col, Image())\n",
    "# batch = batch.map(tx, input_columns=cfg.x_col, num_proc=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': Value(dtype='string', id=None),\n",
       " 'label_idx': Value(dtype='int64', id=None),\n",
       " 'image_name': Value(dtype='string', id=None),\n",
       " 'organ': Value(dtype='string', id=None),\n",
       " 'species_id': Value(dtype='int64', id=None),\n",
       " 'obs_id': Value(dtype='int64', id=None),\n",
       " 'author': Value(dtype='string', id=None),\n",
       " 'altitude': Value(dtype='float64', id=None),\n",
       " 'latitude': Value(dtype='float64', id=None),\n",
       " 'longitude': Value(dtype='float64', id=None),\n",
       " 'species': Value(dtype='string', id=None),\n",
       " 'genus': Value(dtype='string', id=None),\n",
       " 'family': Value(dtype='string', id=None),\n",
       " 'learn_tag': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[479, 489, 490, 491, 492, 493, 495, 496, 497, 498]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_ds.take(10)[\"__index_level_0__\"]\n",
    "# ds = HFDataset.from_dict({\"image\": image_paths, \"file_path\": image_paths})\n",
    "# ds = ds.cast_column(\"image\", Image())\n",
    "# ds = ds.cast_column(\"file_path\", Value(\"string\"))\n",
    "# metadata.info(verbose=True)\n",
    "# metadata[keep_cols].info(verbose=True)\n",
    "# metadata[\"gbif_species_id\"].nunique()\n",
    "# metadata[\"species_id\"].nunique()\n",
    "\n",
    "# metadata[\"gbif_species_id\"].isna().sum()\n",
    "# metadata[\"species_id\"].isna().sum()\n",
    "# metadata.head(3)\n",
    "# metadata.describe(include=\"all\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running torch_pipeline with HFPlantDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_sdk/helpers.py:48: UserWarning: A newer version of lightning-sdk is available (0.2.14). Please consider upgrading with `pip install -U lightning-sdk`. Not all platform functionality can be guaranteed to work with the current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Config</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">use_grid</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">grid_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">image_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">cpu_count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">root_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">dataset_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/competition-metadata/PlantCLEF2</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">025_test_images/PlantCLEF2025_test_images'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hf_dataset_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/parquet/plantclef2025/full_test/HF_dataset</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">embeddings_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">test_embeddings_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">folder_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test_grid_3x3_embeddings'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">test_embeddings_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/t</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">est_grid_3x3_embeddings'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">test_submission_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/t</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">est_grid_3x3_embeddings-submission.csv'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">config_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/test_grid_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">3x3_embeddings-config.json'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33muse_grid\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mgrid_size\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "    \u001b[33mimage_size\u001b[0m=\u001b[1;36m546\u001b[0m,\n",
       "    \u001b[33mbatch_size\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
       "    \u001b[33mcpu_count\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
       "    \u001b[33mtop_k\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
       "    \u001b[33mdevice\u001b[0m=\u001b[32m'cpu'\u001b[0m,\n",
       "    \u001b[33mroot_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025'\u001b[0m,\n",
       "    \u001b[33mdataset_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/competition-metadata/PlantCLEF2\u001b[0m\n",
       "\u001b[32m025_test_images/PlantCLEF2025_test_images'\u001b[0m,\n",
       "    \u001b[33mhf_dataset_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/parquet/plantclef2025/full_test/HF_dataset\u001b[0m\n",
       "\u001b[32m'\u001b[0m,\n",
       "    \u001b[33membeddings_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings'\u001b[0m,\n",
       "    \u001b[33mtest_embeddings_dir\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test'\u001b[0m,\n",
       "    \u001b[33mfolder_name\u001b[0m=\u001b[32m'test_grid_3x3_embeddings'\u001b[0m,\n",
       "    \u001b[33mtest_embeddings_path\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/t\u001b[0m\n",
       "\u001b[32mest_grid_3x3_embeddings'\u001b[0m,\n",
       "    \u001b[33mtest_submission_path\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/t\u001b[0m\n",
       "\u001b[32mest_grid_3x3_embeddings-submission.csv'\u001b[0m,\n",
       "    \u001b[33mconfig_path\u001b[0m=\u001b[32m'/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/test_grid_\u001b[0m\n",
       "\u001b[32m3x3_embeddings-config.json'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plantclef.embed.workflow import Config\n",
    "from plantclef.embed.utils import print_dir_size\n",
    "import os\n",
    "\n",
    "cfg = Config()\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quadrat_id</th>\n",
       "      <th>species_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-CEV3-20240602</td>\n",
       "      <td>[1654010, 1395063, 1392662, 1414387, 1743646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-PdlC-A1-20130807</td>\n",
       "      <td>[1744569, 1361917, 1356350, 1418612, 1361129]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-A1-20130903</td>\n",
       "      <td>[1744569, 1392608, 1361382, 1361068, 1361971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-PdlC-A1-20140721</td>\n",
       "      <td>[1529289, 1374758, 1402995, 1741880, 1362066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-A1-20140811</td>\n",
       "      <td>[1361281, 1418612, 1356350, 1392608, 1722440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>RNNB-8-5-20240118</td>\n",
       "      <td>[1361437, 1655199, 1357049, 1722441, 1414356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>RNNB-8-6-20240118</td>\n",
       "      <td>[1655199, 1363434, 1359297, 1357962, 1361703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>RNNB-8-7-20240118</td>\n",
       "      <td>[1359297, 1356521, 1363553, 1357358, 1362711]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>RNNB-8-8-20240118</td>\n",
       "      <td>[1359650, 1396330, 1743962, 1357962, 1388788]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>RNNB-8-9-20240118</td>\n",
       "      <td>[1655199, 1361437, 1363553, 1357049, 1426005]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quadrat_id                                    species_ids\n",
       "0       2024-CEV3-20240602  [1654010, 1395063, 1392662, 1414387, 1743646]\n",
       "1     CBN-PdlC-A1-20130807  [1744569, 1361917, 1356350, 1418612, 1361129]\n",
       "2     CBN-PdlC-A1-20130903  [1744569, 1392608, 1361382, 1361068, 1361971]\n",
       "3     CBN-PdlC-A1-20140721  [1529289, 1374758, 1402995, 1741880, 1362066]\n",
       "4     CBN-PdlC-A1-20140811  [1361281, 1418612, 1356350, 1392608, 1722440]\n",
       "...                    ...                                            ...\n",
       "2100     RNNB-8-5-20240118  [1361437, 1655199, 1357049, 1722441, 1414356]\n",
       "2101     RNNB-8-6-20240118  [1655199, 1363434, 1359297, 1357962, 1361703]\n",
       "2102     RNNB-8-7-20240118  [1359297, 1356521, 1363553, 1357358, 1362711]\n",
       "2103     RNNB-8-8-20240118  [1359650, 1396330, 1743962, 1357962, 1388788]\n",
       "2104     RNNB-8-9-20240118  [1655199, 1361437, 1363553, 1357049, 1426005]\n",
       "\n",
       "[2105 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(cfg.test_submission_path)\n",
    "\n",
    "df = df.assign(quadrat_id=df[\"quadrat_id\"].apply(lambda x: os.path.splitext(x)[0]))\n",
    "\n",
    "df.to_csv(cfg.test_submission_path, sep=\",\", index=False, quoting=csv.QUOTE_ALL)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing disk usage of directory: /teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/test_grid_3x3_embeddings\n",
      "Directory Disk Usage: 543M\t/teamspace/studios/this_studio/plantclef-vision/data/plantclef2025/embeddings/full_test/test_grid_3x3_embeddings\n",
      "2025-05-08 08:42:53\n"
     ]
    }
   ],
   "source": [
    "print_dir_size(cfg.test_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33614/1293469598.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.apply(select_top_k_unique_logits, top_k=top_k).rename(\"logits\").reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-CEV3-20240602.jpg</td>\n",
       "      <td>[(1654010, 0.44266772270202637), (1395063, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBN-PdlC-A1-20130807.jpg</td>\n",
       "      <td>[(1744569, 0.2301855832338333), (1361917, 0.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBN-PdlC-A1-20130903.jpg</td>\n",
       "      <td>[(1744569, 0.16917195916175842), (1392608, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBN-PdlC-A1-20140721.jpg</td>\n",
       "      <td>[(1529289, 0.14910352230072021), (1374758, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBN-PdlC-A1-20140811.jpg</td>\n",
       "      <td>[(1361281, 0.12936192750930786), (1418612, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>RNNB-8-5-20240118.jpg</td>\n",
       "      <td>[(1361437, 0.7179210782051086), (1655199, 0.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>RNNB-8-6-20240118.jpg</td>\n",
       "      <td>[(1655199, 0.37736761569976807), (1363434, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>RNNB-8-7-20240118.jpg</td>\n",
       "      <td>[(1359297, 0.30361855030059814), (1356521, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>RNNB-8-8-20240118.jpg</td>\n",
       "      <td>[(1359650, 0.3005388379096985), (1396330, 0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>RNNB-8-9-20240118.jpg</td>\n",
       "      <td>[(1655199, 0.21261119842529297), (1361437, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_name  \\\n",
       "0       2024-CEV3-20240602.jpg   \n",
       "1     CBN-PdlC-A1-20130807.jpg   \n",
       "2     CBN-PdlC-A1-20130903.jpg   \n",
       "3     CBN-PdlC-A1-20140721.jpg   \n",
       "4     CBN-PdlC-A1-20140811.jpg   \n",
       "...                        ...   \n",
       "2100     RNNB-8-5-20240118.jpg   \n",
       "2101     RNNB-8-6-20240118.jpg   \n",
       "2102     RNNB-8-7-20240118.jpg   \n",
       "2103     RNNB-8-8-20240118.jpg   \n",
       "2104     RNNB-8-9-20240118.jpg   \n",
       "\n",
       "                                                 logits  \n",
       "0     [(1654010, 0.44266772270202637), (1395063, 0.3...  \n",
       "1     [(1744569, 0.2301855832338333), (1361917, 0.22...  \n",
       "2     [(1744569, 0.16917195916175842), (1392608, 0.1...  \n",
       "3     [(1529289, 0.14910352230072021), (1374758, 0.1...  \n",
       "4     [(1361281, 0.12936192750930786), (1418612, 0.1...  \n",
       "...                                                 ...  \n",
       "2100  [(1361437, 0.7179210782051086), (1655199, 0.52...  \n",
       "2101  [(1655199, 0.37736761569976807), (1363434, 0.2...  \n",
       "2102  [(1359297, 0.30361855030059814), (1356521, 0.2...  \n",
       "2103  [(1359650, 0.3005388379096985), (1396330, 0.28...  \n",
       "2104  [(1655199, 0.21261119842529297), (1361437, 0.2...  \n",
       "\n",
       "[2105 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top_1 = []\n",
    "# top_2 = []\n",
    "# top_3 = []\n",
    "# top_4 = []\n",
    "# top_5 = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     top_1.append(row[\"logits\"][0])\n",
    "#     top_2.append(row[\"logits\"][1])\n",
    "#     top_3.append(row[\"logits\"][2])\n",
    "#     top_4.append(row[\"logits\"][3])\n",
    "#     top_5.append(row[\"logits\"][4])\n",
    "\n",
    "#     print(i)\n",
    "#     # pprint(row)\n",
    "\n",
    "#     if i >= 5:\n",
    "#         break\n",
    "\n",
    "# print(f\"top_1: {top_1}\")\n",
    "# print(f\"top_2: {top_2}\")\n",
    "# print(f\"top_3: {top_3}\")\n",
    "# print(f\"top_4: {top_4}\")\n",
    "# print(f\"top_5: {top_5}\")\n",
    "# top_species_ids = [s_id for s_id, _ in [*top_1, *top_2, *top_3, *top_4, *top_5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings and logits from model.predict_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image names from HFDataset -> Create a pandas DataFrame to match image names to logits + embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting embeddings from single-label training images\n",
    "\n",
    "We extract embeddings from a small subset of training images to validate our pipeline.  \n",
    "We don't perform tiling on the train images (we use the full image) and extract 768-dimensional ViT embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding test images with tiling (3x3)\n",
    "\n",
    "\n",
    "Since the test images are high-resolution and contain multiple plant species, we split them into a 3x3 grid of tiles.\n",
    "- We **extract embeddings** and **top-*K* logits** from each tile using the ViT model.  \n",
    "- This **patch-wise representation** is critical for enabling multi-label classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing classifier logits per tile\n",
    "\n",
    "For each tile, we look at the **top predicted species** and associated confidence scores (`logits`).  \n",
    "This helps interpret how confident the model is in identifying species in each patch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding the entire test set with tiling\n",
    "\n",
    "We scale up our embedding pipeline to process the full test dataset using **3x3 tiling**.  \n",
    "This prepares the data for the downstream tasks of efficient **nearest neighbor search** and **multi-label prediction** at the tile level."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving test embeddings and logits to Parquet\n",
    "\n",
    "We serialize the full test embeddings into partitioned Parquet files for later use in inference pipelines.  \n",
    "The logits are stored as JSON strings for flexibility."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the full training set (no tiling)\n",
    "\n",
    "We repeat the embedding process on the **full training dataset**, this time *without tiling*.  \n",
    "This enables us to use the embeddings directly or as a **transfer learning** approach in a Faiss-based nearest neighbor retrieval system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the training embeddings to Parquet\n",
    "\n",
    "Finally, we save the full training embeddings in partitioned Parquet format to support fast, distributed retrieval during inference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Ready for Downstream Use\n",
    "\n",
    "We now have rich ViT embeddings for both train and test datasets, ready for use in:\n",
    "- Multi-label classification\n",
    "- Retrieval-based inference\n",
    "- Nearest Neighbor Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
